## ğŸ¯ What I Created

A custom tokenizer in JavaScript that learns vocab from text, supports ENCODE/DECODE and handles special tokens.

## ğŸ“ Project Structure

```
src/
â”œâ”€â”€ types/index.ts          # TypeScript type definitions
â”œâ”€â”€ utils/tokenizer.ts      # Core tokenizer logic
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ TrainingSection.tsx # Training interface
â”‚   â”œâ”€â”€ TestingSection.tsx  # Encoding/decoding interface  
â”‚   â””â”€â”€ VocabSection.tsx    # Vocabulary explorer
â”œâ”€â”€ App.tsx                 # Main application
â”œâ”€â”€ index.tsx              # React entry point
â””â”€â”€ index.css              # Tailwind CSS styles
```

## ğŸ”§ Core Features

### 1. **Custom Tokenizer Engine**
- **Vocabulary Learning**: Builds vocabulary from training text
- **Frequency-based Selection**: Prioritizes most common words
- **Special Token Support**: Handles ``, ``, ``, ``
- **Text Preprocessing**: Converts text to lowercase, removes punctuation
- **Configurable Size**: Adjustable vocabulary size limits

### 2. **Three Main Sections**

#### ğŸ“š **Training Section**
- Text input for training data
- Sample data loader
- Real-time training feedback
- Vocabulary statistics display

#### ğŸ§ª **Testing Section** 
- Text encoding to token IDs
- Token ID decoding back to text
- Visual token breakdown with color coding
- Round-trip validation

#### ğŸ“– **Vocabulary Section**
- Statistics view (vocab size, token counts)
- Complete vocabulary browser
- Special vs regular token separation
- Tabbed interface for organization

## âš™ï¸ How It Works

### **Step 1: Training Process**
```typescript
// User enters training text like:
"Hello world this is a test"
"JavaScript is a programming language"

// Tokenizer processes:
1. Splits into words: ["hello", "world", "this", "is", "a", "test", ...]
2. Counts frequencies: {"hello": 1, "world": 1, "is": 2, ...}
3. Sorts by frequency and builds vocabulary
4. Assigns unique IDs: {"": 0, "": 1, "": 2, "is": 3, ...}
```

### **Step 2: Encoding Process**
```typescript
// Input: "Hello world"
// Process:
1. Tokenize: ["hello", "world"]
2. Map to IDs: [5, 12] (from vocabulary)
3. Add special tokens: [0, 5, 12, 1] (, hello, world, )
// Output: [0, 5, 12, 1]
```

### **Step 3: Decoding Process**
```typescript
// Input: [0, 5, 12, 1]
// Process:
1. Map IDs back to tokens: ["", "hello", "world", ""]
2. Filter out special tokens: ["hello", "world"]
3. Join with spaces: "hello world"
// Output: "hello world"
```

## ğŸ”„ Data Flow

```
1. User Input (Training Text)
   â†“
2. Tokenizer.learnVocab()
   â†“
3. Vocabulary Created
   â†“
4. User Input (Test Text)
   â†“
5. Tokenizer.encode()
   â†“
6. Token IDs Generated
   â†“
7. Tokenizer.decode()
   â†“
8. Original Text Recovered
```

## ğŸš€ How to Use

1. **Train**: Enter training text â†’ Click "Train Tokenizer"
2. **Test**: Enter test text â†’ Click "Encode" â†’ Click "Decode"
3. **Explore**: View statistics and vocabulary in the third section
4. **Demo**: Click "Run Demo" for a quick demonstration